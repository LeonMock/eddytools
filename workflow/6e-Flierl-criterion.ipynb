{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ce76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from geopy.distance import geodesic\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4305d06c",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tracking_start, tracking_end = \"2012-01-01\", \"2012-12-31\"\n",
    "\n",
    "experiment_name = 'INALT20r.L120-KRS006'#'INALT60.L120-KRS0020' #\n",
    "data_resolution = '1d'\n",
    "\n",
    "OW_thr_factor =-0.3\n",
    "first_or_last_crossing = 'first'\n",
    "minimum_duration = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9bc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_name.startswith(\"INALT60\"):\n",
    "    prefix = \"2_\"\n",
    "    Npix_min, Npix_max = 720, 18000\n",
    "    sigma = 15\n",
    "    wx = 600\n",
    "    ds_name = \"inalt60\"\n",
    "    OW_end = 20120125\n",
    "elif experiment_name.startswith(\"INALT20\"):\n",
    "    prefix = \"1_\"\n",
    "    Npix_min, Npix_max = 80, 2000\n",
    "    sigma = 5\n",
    "    wx = 200\n",
    "    ds_name = \"inalt20r\"\n",
    "    OW_end = 20120219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5643be5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 [(0, 0), (21, 10), (54, 18), (91, 24), (132, 29), (173, 33), (210, 36), (253, 39), (286, 41), (323, 43), (365, 45), (412, 47), (465, 49), (525, 51), (592, 53), (668, 55), (753, 57), (848, 59), (952, 61), (1066, 63), (1189, 65), (1321, 67), (1461, 69), (1608, 71), (1762, 73), (1922, 75), (2086, 77), (2255, 79), (2428, 81), (2603, 83), (2782, 85), (2963, 87), (3146, 89), (3331, 91), (3518, 93), (3706, 95), (3896, 97), (4086, 99), (4279, 101), (4472, 103), (4666, 105), (4861, 107), (5057, 109), (5254, 111), (5452, 113), (5651, 115), (5850, 117), (6050, 119)]\n"
     ]
    }
   ],
   "source": [
    "#depth= 0  #corresponding to... \n",
    "#depth_index = 0 \n",
    "\n",
    "mesh_mask = xr.open_dataset(f'/gxfs_work/geomar/smomw523/smoothed_data/{experiment_name}/{prefix}{experiment_name}_mesh_mask.nc')\n",
    "nav_lat = mesh_mask['nav_lat'].values  # shape (y, x)\n",
    "nav_lon = mesh_mask['nav_lon'].values\n",
    "\n",
    "indices = np.concatenate((range(0, 11, 10),range(18, 25, 6),range(29, 34, 4),range(36, 40, 3),range(41, 120, 2)))\n",
    "depth_information = [(round(mesh_mask.nav_lev.values[i]), i) for i in indices]\n",
    "print(len(depth_information),depth_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048713cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vel = xr.open_mfdataset(f'/gxfs_work/geomar/smomw523/processed_data/{experiment_name}/velocity/{ds_name}-{data_resolution}-velocity-*.nc').vel\n",
    "OW_exp = xr.open_dataset(f'/gxfs_work/geomar/smomw523/eddytools/results/{experiment_name}/smoothed/{sigma}/{data_resolution}/depth-0/OW_20120101_{OW_end}_rolling-{wx}.nc').OW.isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c085d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [14:36<00:00, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /gxfs_work/geomar/smomw523/eddytools/results/INALT60.L120-KRS0020/smoothed/15/1d/depth-6050/Tracks-crossed_20120101_20121231_OW0.3_Npix-720-18000_rolling-600.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_diameter, min_duration = 50, 10\n",
    "filename = f'Tracks-crossed_{tracking_start.replace(\"-\", \"\")}_{tracking_end.replace(\"-\", \"\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.pickle'\n",
    "\n",
    "with open(f'/gxfs_work/geomar/smomw523/eddytools/results/{experiment_name}/smoothed/{sigma}/{data_resolution}/Flierl-criterion_for-crossed-eddies-more-than-{min_diameter}km-{min_duration}days_{tracking_start.replace(\"-\", \"\")}_{tracking_end.replace(\"-\", \"\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['track_ix', 'type', 'lon', 'lat', 'time', 'duration',\n",
    "                     'depth', 'rotational_velocity', 'translational_velocity', 'Flierl_criterion',\n",
    "                     'amp', 'scale', 'area', 'section'])\n",
    "        \n",
    "    for (depth, depth_index) in tqdm(depth_information): # depth_information\n",
    "        datapath = f'/gxfs_work/geomar/smomw523/eddytools/results/{experiment_name}/smoothed/{sigma}/{data_resolution}/depth-{depth}/'\n",
    "        filepath = datapath + filename\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found: {filepath}\")\n",
    "            continue\n",
    "        tracks = np.load(datapath + filename, allow_pickle=True)\n",
    "        df = pd.read_csv(datapath + f'Good-hope-{first_or_last_crossing}-crossings_min-{minimum_duration}d_{tracking_start.replace(\"-\", \"\")}_{tracking_end.replace(\"-\", \"\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.csv')\n",
    "\n",
    "        for track_ix, track in enumerate(tracks):\n",
    "            if track['scale'].max() < min_diameter or len(track['time']) < min_duration:\n",
    "                continue\n",
    "            #else:\n",
    "            speeds = [0]\n",
    "            times, lons, lats = track['time'], track['lon'], track['lat']\n",
    "            for i in range(1, len(times)):\n",
    "                dist_km = geodesic((lats[i-1], lons[i-1]), (lats[i], lons[i])).m\n",
    "                speed = dist_km / 86400\n",
    "                speeds.append(speed)\n",
    "            track['speed'] = np.array(speeds)\n",
    "\n",
    "            if df.loc[track_ix, 'section']!='Ansorge-GHS':\n",
    "                continue # crossing wrong section\n",
    "\n",
    "            target_time = pd.to_datetime(df.loc[track_ix, 'time']) + timedelta(hours=12)\n",
    "            matching_index = (times == target_time).nonzero()[0]\n",
    "            if len(matching_index) != 1:\n",
    "                if len(matching_index) == 0:\n",
    "                    print(f\"Warning: Track crosses section at first detected timestep (no velocity to calculate). Skip. ({depth}, {track_ix})\")\n",
    "                elif len(matching_index) == None:\n",
    "                    print(f\"Warning: Times from track and crossing.csv do not match. Skip. ({depth}, {track_ix})\")\n",
    "                elif len(matching_index) > 1: # should not be possible\n",
    "                    print(f\"Warning: More than one matching timestep. Skip. ({depth}, {track_ix})\") \n",
    "                continue\n",
    "            else:\n",
    "                translat_vel = track['speed'][matching_index]\n",
    "\n",
    "            eddies = np.load(datapath + f'Eddies_{target_time.strftime(\"%Y-%m-%d\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.pickle', allow_pickle=True)\n",
    "\n",
    "            rot_vel = None\n",
    "            for eddy_ix in range(len(eddies)):\n",
    "                eddy = eddies[eddy_ix]\n",
    "                if np.abs(eddy['lon'][0] - df.loc[track_ix, 'lon']) < 1e-3 and np.abs(eddy['lat'][0] - df.loc[track_ix, 'lat']) < 1e-3:\n",
    "                    ds_vel_slice = ds_vel.isel(depth=depth_index).sel(time_counter=target_time)\n",
    "\n",
    "                    eddy_lat = OW_exp['lat'].values[eddy['eddy_j']]\n",
    "                    eddy_lon = OW_exp['lon'].values[eddy['eddy_i']]\n",
    "                    eddy_coords = np.column_stack((eddy_lat, eddy_lon))\n",
    "                    flat_latlon = np.column_stack((nav_lat.ravel(), nav_lon.ravel()))\n",
    "                    tree = cKDTree(flat_latlon)\n",
    "                    _, indices = tree.query(eddy_coords)\n",
    "                    ys, xs = np.unravel_index(indices, nav_lat.shape)\n",
    "                    mask = np.zeros(ds_vel_slice.shape, dtype=bool)\n",
    "                    mask[ys, xs] = True\n",
    "                    masked_vel = ds_vel_slice.where(mask) \n",
    "                    if masked_vel.count() == 0:\n",
    "                        print(f\"Warning: No mask for eddy. Skip. ({depth}, {track_ix}, {eddy_ix})\")\n",
    "                        continue # should not be possible\n",
    "                    rot_vel = masked_vel.fillna(0).values.max()\n",
    "                    Flierl_vel = rot_vel / translat_vel\n",
    "                    writer.writerow([track_ix, track['type'], df.loc[track_ix, 'lon'], df.loc[track_ix, 'lat'], df.loc[track_ix, 'time'], df.loc[track_ix, 'duration'],\n",
    "                        depth, rot_vel, translat_vel[0], Flierl_vel[0],\n",
    "\t                    df.loc[track_ix, 'amp'], df.loc[track_ix, 'scale'], df.loc[track_ix, 'area'], df.loc[track_ix, 'section']])\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            if rot_vel is None:\n",
    "                print(f\"Warning: No eddy found along track. Skip. ({depth}, {track_ix})\") # should not be possible\n",
    "                continue\n",
    "\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            pickle.dump(tracks, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f8888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [04:50,  5.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# surface eddy as column downward\n",
    " \n",
    "min_diameter, min_duration = 50, 10\n",
    "filename = f'Tracks-crossed_{tracking_start.replace(\"-\", \"\")}_{tracking_end.replace(\"-\", \"\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.pickle'\n",
    "\n",
    "with open(f'/gxfs_work/geomar/smomw523/eddytools/results/{experiment_name}/smoothed/{sigma}/{data_resolution}/Flierl-criterion-column_for-crossed-eddies-more-than-{min_diameter}km-{min_duration}days_{tracking_start.replace(\"-\", \"\")}_{tracking_end.replace(\"-\", \"\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['track_ix', 'type', 'lon', 'lat', 'time', 'duration',\n",
    "                     'depth', 'rotational_velocity', 'translational_velocity', 'Flierl_criterion',\n",
    "                     'amp', 'scale', 'area', 'section'])\n",
    "    \n",
    "    datapath = f'/gxfs_work/geomar/smomw523/eddytools/results/{experiment_name}/smoothed/{sigma}/{data_resolution}/depth-0/' #surface\n",
    "    filepath = datapath + filename\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File not found: {filepath}\")\n",
    "    \n",
    "    tracks = np.load(datapath + filename, allow_pickle=True)\n",
    "    \n",
    "    df = pd.read_csv(datapath + f'Good-hope-{first_or_last_crossing}-crossings_min-{minimum_duration}d_{tracking_start.replace(\"-\", \"\")}_{tracking_end.replace(\"-\", \"\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.csv')\n",
    "    print(len(tracks))\n",
    "    for track_ix, track in tqdm(enumerate(tracks)):\n",
    "        if track['scale'].max() < min_diameter or len(track['time']) < min_duration:\n",
    "            continue\n",
    "            #else:\n",
    "        speeds = [0]\n",
    "        times, lons, lats = track['time'], track['lon'], track['lat']\n",
    "        for i in range(1, len(times)):\n",
    "            dist_km = geodesic((lats[i-1], lons[i-1]), (lats[i], lons[i])).m\n",
    "            speed = dist_km / 86400\n",
    "            speeds.append(speed)\n",
    "        track['speed'] = np.array(speeds)\n",
    "\n",
    "        if df.loc[track_ix, 'section']!='Ansorge-GHS':\n",
    "            continue # crossing wrong section\n",
    "\n",
    "        target_time = pd.to_datetime(df.loc[track_ix, 'time']) + timedelta(hours=12)\n",
    "        matching_index = (times == target_time).nonzero()[0]\n",
    "        if len(matching_index) != 1:\n",
    "            if len(matching_index) == 0:\n",
    "                print(f\"Warning: Track crosses section at first detected timestep (no velocity to calculate). Skip. ({depth}, {track_ix})\")\n",
    "            elif len(matching_index) == None:\n",
    "                print(f\"Warning: Times from track and crossing.csv do not match. Skip. ({depth}, {track_ix})\")\n",
    "            elif len(matching_index) > 1: # should not be possible\n",
    "                print(f\"Warning: More than one matching timestep. Skip. ({depth}, {track_ix})\") \n",
    "            continue\n",
    "        else:\n",
    "            translat_vel = track['speed'][matching_index]\n",
    "\n",
    "        eddies = np.load(datapath + f'Eddies_{target_time.strftime(\"%Y-%m-%d\")}_OW{np.abs(OW_thr_factor)}_Npix-{Npix_min}-{Npix_max}_rolling-{wx}.pickle', allow_pickle=True) #surface\n",
    "        for (depth, depth_index) in depth_information:\n",
    "            rot_vel = None\n",
    "            for eddy_ix in range(len(eddies)):\n",
    "                eddy = eddies[eddy_ix]\n",
    "                if np.abs(eddy['lon'][0] - df.loc[track_ix, 'lon']) < 1e-3 and np.abs(eddy['lat'][0] - df.loc[track_ix, 'lat']) < 1e-3:\n",
    "                    ds_vel_slice = ds_vel.isel(depth=depth_index).sel(time_counter=target_time)\n",
    "\n",
    "                    eddy_lat = OW_exp['lat'].values[eddy['eddy_j']]\n",
    "                    eddy_lon = OW_exp['lon'].values[eddy['eddy_i']]\n",
    "                    eddy_coords = np.column_stack((eddy_lat, eddy_lon))\n",
    "                    flat_latlon = np.column_stack((nav_lat.ravel(), nav_lon.ravel()))\n",
    "                    tree = cKDTree(flat_latlon)\n",
    "                    _, indices = tree.query(eddy_coords)\n",
    "                    ys, xs = np.unravel_index(indices, nav_lat.shape)\n",
    "                    mask = np.zeros(ds_vel_slice.shape, dtype=bool)\n",
    "                    mask[ys, xs] = True\n",
    "                    masked_vel = ds_vel_slice.where(mask) \n",
    "                    if masked_vel.count() == 0:\n",
    "                        print(f\"Warning: No mask for eddy. Skip. ({depth}, {track_ix}, {eddy_ix})\")\n",
    "                        continue # should not be possible\n",
    "                    rot_vel = masked_vel.fillna(0).values.max()\n",
    "                    Flierl_vel = rot_vel / translat_vel\n",
    "                    writer.writerow([track_ix, track['type'], df.loc[track_ix, 'lon'], df.loc[track_ix, 'lat'], df.loc[track_ix, 'time'], df.loc[track_ix, 'duration'],\n",
    "                        depth, rot_vel, translat_vel[0], Flierl_vel[0],\n",
    "\t                    df.loc[track_ix, 'amp'], df.loc[track_ix, 'scale'], df.loc[track_ix, 'area'], df.loc[track_ix, 'section']])\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            if rot_vel is None:\n",
    "                print(f\"Warning: No eddy found along track. Skip. ({depth}, {track_ix})\") # should not be possible\n",
    "                continue\n",
    "\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            pickle.dump(tracks, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cb5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-eddytools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
