{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc276754-649e-4a8f-9b5d-3047f25a2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import xgcm\n",
    "\n",
    "from xorca.lib import load_xorca_dataset\n",
    "import pickle\n",
    "import eddytools as et\n",
    "from cmocean import cm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "# Obviously it is not a great idea to ignore warnings, however there are quite many\n",
    "# RuntimeWarnings because of division by 0 in some parts of this notebook. To keep\n",
    "# the instructive nature of this example notebook, these warnings are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a7bfb1-0a2d-42fd-9cb4-5a4548ab974b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/usr/shkifmzb/notebooks/shared-notebooks/hiwi/old_std'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff383e37-2b73-4542-9ea5-de43d232202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskpath = '/scratch/usr/shkifmzb/ORION10/'\n",
    "meshpath = [maskpath + '1_mesh_mask.nc']\n",
    "mask_acc = xr.open_dataset('/scratch/usr/shkifmmp/master/data/ORION10/interpolated/int_mask_regions.nc').mask_regions\n",
    "def data_for_det(exp, years):\n",
    "    '''years =[year1, year2], exp = 5 or 6 '''\n",
    "    datapath = '/scratch/usr/shklvn09/SCRATCH/ORION10.L46.LIM2vp.CFCSF6.MOPS.JRA.XIOS2.5.LP01-EXP0'+str(exp)+'/OUT/chunked_for_EDT/'\n",
    "    data_in = [sorted(glob(datapath + '*'+str(year)+'0101_'+str(year)+'1231_grid_[TUV]_chunked_1klev.nc')) for year in range (years[0],years[-1])]\n",
    "    return data_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea2ba1a-ebd5-4458-a8f3-4285fa8d74ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = [2014, 2016]\n",
    "data_in =data_for_det(5, date)\n",
    "len(data_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa60d770-e406-4211-b756-a9102181b159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2014, 2016]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f48a53f-9d70-466d-9294-be7fe21277de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter(data_in, years):\n",
    "    data=[]\n",
    "# define metrics for xgcm (not strictly necessary)\n",
    "    for i in range(0,len(data_in)):\n",
    "        data1 = load_xorca_dataset(data_files=data_in[i], aux_files=meshpath, model_config='NEST',\n",
    "               input_ds_chunks = {\"time_counter\": 1, \"t\": 1,\n",
    "                              \"z\": 1, \"deptht\": 1, \"depthu\": 1, \"depthv\": 1, \"depthw\": 1,\n",
    "                              \"x\": 1002, \"y\": 629},\n",
    "               target_ds_chunks = {\"t\": 1,\n",
    "                               \"z_c\": 1, \"z_l\": 1,\n",
    "                               \"x_c\": 1002, \"x_r\": 1002, \"y_c\": 629, \"y_r\": 629})\n",
    "        at, au = data1['e1t'] * data1['e2t'], data1['e1u'] * data1['e2u'] \n",
    "        av, af = data1['e1v'] * data1['e2v'], data1['e1f'] * data1['e2f'] \n",
    "        vt, vu, vv, vw = data1['e3t'] * at, data1['e3u'] * au, data1['e3v'] * av, data1['e3w'] * at \n",
    "\n",
    "        data1 = data1.update({'at': at, 'au': au, 'av': av, 'af': af, 'vt': vt, 'vu': vu, 'vv': vv, 'vw': vw})\n",
    "        data1 = data1.set_coords(['at', 'au', 'av', 'af', 'vt', 'vu', 'vv', 'vw'])\n",
    "        data.append(data1)\n",
    "    metrics = {\n",
    "        ('X',): ['e1t', 'e1u', 'e1v', 'e1f'], # X distances\n",
    "        ('Y',): ['e2t', 'e2u', 'e2v', 'e2f'], # Y distances\n",
    "#    ('Z',): ['e3t', 'e3u', 'e3v', 'e3w'], # Z distances\n",
    "        ('X', 'Y'): ['at', 'au', 'av', 'af'], # Areas\n",
    "#    ('X', 'Y', 'Z'): ['vt', 'vu', 'vv', 'vw'] # Volumes\n",
    "    }\n",
    "    \n",
    "    bathy = xr.open_mfdataset('../Bathymetry.nc')\n",
    "    #mask_acc = xr.open_dataset('/scratch/usr/shkifmmp/master/data/ORION10/mask/mask_nest_int_2d.nc')\n",
    "    #data = [data[i].update({'mask_acc': (['y_c', 'x_c'], mask_acc['mask_nest'].data)}) for i in range(0,len(data_in))]\n",
    "    #ice= xr.open_mfdataset('../interpolated_Sea_Ice_1958_2018/Sea_Ice_on_fpoint_1959.nc')\n",
    "    data = [data[i].update({'bathymetry': (['y_r', 'x_r'], bathy['Bathymetry'].data)}) for i in range(0,len(data_in))]\n",
    "    #data = data.update({'ileadfra': (['t','y_r', 'x_r'], ice['ileadfra'].data)})\n",
    "    grid = [xgcm.Grid(data[i], metrics=metrics) for i in range(0,len(data_in))]\n",
    "    \n",
    "   # Calculate vorticity and Okubo-Weiss parameter and make sure the chunk sizes are as before.\n",
    "\n",
    "    data_OW = [et.okuboweiss.calc(data[i].isel(z_c=9, z_l=9), grid[i],\n",
    "                             'vozocrtx', 'vomecrty').chunk({'x_c': 1002, 'x_r': 1002,\n",
    "                                                            'y_c': 629, 'y_r': 629}) for i in range(0,len(data_in))]\n",
    "    \n",
    "    # Merge the new variables `OW` and `vort` to the dataset `data`\n",
    "    data = [xr.merge([data[i], data_OW[i]], compat='override') for i in range(0,len(data_in))]\n",
    "    \n",
    "    interpolation_parameters = [{'model': 'ORCA',\n",
    "                            'grid': 'latlon',\n",
    "                            'start_time': str(years[0])+'-01-01', # time range start\n",
    "                            'end_time': str(years[-1])+'-12-31', # time range end\n",
    "                            'calendar': 'standard', # calendar, must be either 360_day or standard\n",
    "                            'lon1': 77.5, # minimum longitude of detection region\n",
    "                            'lon2': 69.5, # maximum longitude\n",
    "                            'lat1': -67, # minimum latitude\n",
    "                            'lat2': -30, # maximum latitude\n",
    "                            'res': 1./10., # resolution of the fields in degrees\n",
    "                            'vars_to_interpolate': ['OW', 'vort'], # variables to be interpolated \n",
    "                            'mask_to_interpolate': ['fmask', 'tmask', 'bathymetry'], # masks to interpolate\n",
    "                            'regrid_method': 'bilinear', # method used for regridding (default is 'bilinear')\n",
    "                            'ext_method': None} for year in range(years[0],years[-1])]\n",
    "    \n",
    "    data_int, regridder =[] , []\n",
    "\n",
    "    for i in range(0,len(data)):\n",
    "\n",
    "        data_int1, regridder1 = et.interp.horizontal(data[i], metrics, interpolation_parameters[i], weights=None, avoid_regrid=False)\n",
    "        data_int.append(data_int1)\n",
    "        regridder.append(regridder1)\n",
    "    return data_int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319b707d-8999-441d-a355-92f330886149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating from model grid: ORCA\n",
      "No regridding necessary, just interpolating to vorticity grid point.\n",
      "Interpolating OW\n",
      "Interpolating vort\n",
      "Interpolating fmask\n",
      "Interpolating tmask\n",
      "Interpolating bathymetry\n",
      "Interpolating e1f\n",
      "Interpolating e2f\n",
      "Interpolating from model grid: ORCA\n",
      "No regridding necessary, just interpolating to vorticity grid point.\n",
      "Interpolating OW\n",
      "Interpolating vort\n",
      "Interpolating fmask\n",
      "Interpolating tmask\n",
      "Interpolating bathymetry\n",
      "Interpolating e1f\n",
      "Interpolating e2f\n"
     ]
    }
   ],
   "source": [
    "data_int = inter(data_in, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a2eade5-20a4-41ad-b657-8ea18236f0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_int=[data_int[i].compute() for i in range(0,len(data_in))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a615d2f6-8661-4438-8ed6-0305907b59ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from scipy.signal import convolve\n",
    "\n",
    "#def nanconv(a, k, MODE):\n",
    "#    # Flat function for comparison.\n",
    "#    o = np.ones(np.shape(a))\n",
    "#   # Flat function with NaNs for comparison.\n",
    "#   on = np.ones(np.shape(a))\n",
    "#    # Find all the NaNs in the input and replace with 0\n",
    "#    an = np.where(~np.isnan(a), a, 0)\n",
    "#   on = np.where(~np.isnan(a), on, 0)\n",
    "#    # Calculate what a 'flat' function looks like after convolution.\n",
    "#    flat = convolve(on, k, mode=MODE)\n",
    "#   #\n",
    "#   # The line above will automatically include a correction for edge \n",
    "3   # effects,\n",
    "#   # so remove that correction if the user does not want it.\n",
    "#    flat = flat / convolve(o, k, mode=MODE)\n",
    "#    #\n",
    "#    # Do the actual convolution\n",
    "#    output = convolve(an, k, mode=MODE) / flat\n",
    "#    return np.where(~np.isnan(a), output, np.nan)\n",
    "\n",
    "#def spatial_std_zoe(data, wx, wy):\n",
    "#    window = np.ones((1, wy, wx)) / (wy * wx)\n",
    "#    ext = np.zeros(( np.shape(data)[0], \n",
    "#                    np.shape(data)[1] + wy, np.shape(data)[2] + wx))\n",
    "#    ext[:,  int(wy/2):-int(wy/2), int(wx/2):-int(wx/2)] = data\n",
    "#    ext[:,  0:int(wy/2), :] = ext[:, int(wy):int(wy/2):-1, :]\n",
    "#    ext[ :, -int(wy/2)::, :] = ext[ :, -int(wy/2):-int(wy):-1, :]\n",
    "#    ext[ :, :, 0:int(wx/2)] = ext[ :, :, int(wx):int(wx/2):-1]\n",
    "#    ext[ :, :, -int(wx/2)::] = ext[ :, :, -int(wx/2):-int(wx):-1]\n",
    "#    std_tmp1 = np.abs(ext - nanconv(ext, window, \"same\")) ** 2\n",
    "#    std_tmp2 = nanconv(std_tmp1, window, \"same\") ** 0.5\n",
    "#    output =  xr.DataArray(std_tmp2[ :, int(wy/2):-int(wy/2), int(wx/2):-int(wx/2)], \n",
    " #                          coords=data.coords, dims=data.dims).mean(\"time\") \n",
    "#    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf644af9-d255-4f32-9bab-7ca514f2a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_OW_spatial_std = []\n",
    "#for i in range(0,len(data_in)):\n",
    "\n",
    "#    OW_tmp = data_int[i]['OW'].isel(time=slice(0, 20)).compute()#\n",
    "\n",
    "#    OW_tmp = OW_tmp.where(OW_tmp != 0)#\n",
    "\n",
    "#    lon_tmp = OW_tmp['lon'].where(OW_tmp['lon'] > 0, other=OW_tmp['lon'] + 360.)\n",
    "#    OW_tmp=OW_tmp.assign_coords({'lon': lon_tmp})\n",
    "#    wx = 100 # rolling window size in x-direction\n",
    "#    wy = 100 # rolling window size in y-direction\n",
    "#    mean_OW_spatial_std.append(spatial_std_zoe(OW_tmp, wx, wy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e08261e-dfc0-49ae-9a47-ea60c779441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one std for whole SO\n",
    "mean_OW_spatial_std = []\n",
    "\n",
    "for i in range(0,len(data_in)):\n",
    "\n",
    "    OW_tmp = data_int[i]['OW'].compute()\n",
    "\n",
    "    OW_tmp = OW_tmp.where(OW_tmp != 0)\n",
    "\n",
    "    lon_tmp = OW_tmp['lon'].where(OW_tmp['lon'] > 0, other=OW_tmp['lon'] + 360.)\n",
    "    OW_tmp=OW_tmp.assign_coords({'lon': lon_tmp})\n",
    "    mean_OW_spatial_std.append(OW_tmp.std(('lon', 'lat'), skipna=True).mean('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba46bcf-1603-47a5-b89d-4cb0be91b173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583b4d7b-7176-47ed-86cb-d8af673d69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_int = [data_int[i].update({'OW_std': mean_OW_spatial_std[i]}) for i in range(0,len(data_in))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b2a1ed7-7a25-4940-8741-ad966c71b360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xarray.Dataset>\n",
       " Dimensions:     (time: 73, z: 46, lat: 628, lon: 3561)\n",
       " Coordinates:\n",
       "   * time        (time) datetime64[ns] 2014-01-03T12:00:00 ... 2014-12-29T12:0...\n",
       "   * z           (z) int64 1 2 3 4 5 6 7 8 9 10 ... 37 38 39 40 41 42 43 44 45 46\n",
       "   * lat         (lat) float32 -67.96 -67.93 -67.89 ... -29.81 -29.72 -29.63\n",
       "   * lon         (lon) float32 75.5 75.6 75.7 75.8 75.9 ... 71.2 71.3 71.4 71.5\n",
       " Data variables:\n",
       "     OW          (time, lat, lon) float64 9.836e-12 8.819e-13 ... 0.0 0.0\n",
       "     vort        (time, lat, lon) float64 -4.005e-07 -2.538e-07 ... 0.0 0.0\n",
       "     fmask       (z, lat, lon) float64 1.0 1.0 1.0 1.0 1.0 ... 0.0 0.0 0.0 0.0\n",
       "     tmask       (z, lat, lon) float64 1.0 1.0 1.0 1.0 1.0 ... 0.0 0.0 0.0 0.0\n",
       "     bathymetry  (lat, lon) float64 467.2 453.9 453.9 453.9 ... nan nan nan nan\n",
       "     e1f         (lat, lon) float64 4.172e+03 4.172e+03 ... 9.666e+03 9.666e+03\n",
       "     e2f         (lat, lon) float64 4.172e+03 4.172e+03 ... 9.666e+03 9.666e+03\n",
       "     OW_std      float64 1.479e-10,\n",
       " <xarray.Dataset>\n",
       " Dimensions:     (time: 73, z: 46, lat: 628, lon: 3561)\n",
       " Coordinates:\n",
       "   * time        (time) datetime64[ns] 2015-01-03T12:00:00 ... 2015-12-29T12:0...\n",
       "   * z           (z) int64 1 2 3 4 5 6 7 8 9 10 ... 37 38 39 40 41 42 43 44 45 46\n",
       "   * lat         (lat) float32 -67.96 -67.93 -67.89 ... -29.81 -29.72 -29.63\n",
       "   * lon         (lon) float32 75.5 75.6 75.7 75.8 75.9 ... 71.2 71.3 71.4 71.5\n",
       " Data variables:\n",
       "     OW          (time, lat, lon) float64 2.207e-11 7.392e-12 ... 0.0 0.0\n",
       "     vort        (time, lat, lon) float64 1.727e-06 1.442e-06 ... 0.0 0.0\n",
       "     fmask       (z, lat, lon) float64 1.0 1.0 1.0 1.0 1.0 ... 0.0 0.0 0.0 0.0\n",
       "     tmask       (z, lat, lon) float64 1.0 1.0 1.0 1.0 1.0 ... 0.0 0.0 0.0 0.0\n",
       "     bathymetry  (lat, lon) float64 467.2 453.9 453.9 453.9 ... nan nan nan nan\n",
       "     e1f         (lat, lon) float64 4.172e+03 4.172e+03 ... 9.666e+03 9.666e+03\n",
       "     e2f         (lat, lon) float64 4.172e+03 4.172e+03 ... 9.666e+03 9.666e+03\n",
       "     OW_std      float64 1.5e-10]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ecc32-40fa-4bf8-bea7-e3abd353937e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b046d6c2-7a12-4e3f-8fd1-bbd845fbf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters for eddy detection\n",
    "\n",
    "date1= range(date[0], date[-1])\n",
    "detection_parameters= {}\n",
    "for i in range(0,len(date1)):\n",
    "\n",
    "    detection_parameters[i] = {'model': 'ORCA',\n",
    "                        'grid': 'latlon',\n",
    "                        'start_time': str(date1[i])+'-01-01', # time range start\n",
    "                        'end_time': str(date1[i])+'-12-31', # time range end\n",
    "                        'calendar': 'standard', # calendar, must be either 360_day or standard\n",
    "                        'lon1': 77.5, # minimum longitude of detection region\n",
    "                        'lon2': 69.5, # maximum longitude\n",
    "                        'lat1': -67, # minimum latitude\n",
    "                        'lat2': -30, # maximum latitude\n",
    "                        'min_dep': 1000, # minimum ocean depth where to look for eddies in m\n",
    "                        'res': 1./10., # resolution of the fields in degree\n",
    "#                        'OW_thr': data_int['OW_std'].values,s# .values it gives you the numpy array of the values (no informatin on dime and coordinate names\n",
    "                         'OW_thr': data_int[i]['OW_std'].values, #with the 2D std one can remove .values\n",
    "                        'OW_thr_name': 'OW_std', # Okubo-Weiss threshold for eddy detection\n",
    "                        'OW_thr_factor': -0.3, # Okubo-Weiss parameter threshold\n",
    "                        'Npix_min': 10, # minimum number of pixels (grid cells) to be considered as eddy\n",
    "                        'Npix_max': 421, # maximum number of pixels (grid cells)\n",
    "                        'no_long': False, # If True, elongated shapes will not be considered\n",
    "                        'no_two': False # If True, eddies with two minima in the OW\n",
    "                                        # parameter and a OW > OW_thr in between  will not\n",
    "                                        # be considered\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a108886-794b-435a-b532-15cfe62e8f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'model': 'ORCA',\n",
       "  'grid': 'latlon',\n",
       "  'start_time': '2014-01-01',\n",
       "  'end_time': '2014-12-31',\n",
       "  'calendar': 'standard',\n",
       "  'lon1': 77.5,\n",
       "  'lon2': 69.5,\n",
       "  'lat1': -67,\n",
       "  'lat2': -30,\n",
       "  'min_dep': 1000,\n",
       "  'res': 0.1,\n",
       "  'OW_thr': array(1.47853152e-10),\n",
       "  'OW_thr_name': 'OW_std',\n",
       "  'OW_thr_factor': -0.3,\n",
       "  'Npix_min': 10,\n",
       "  'Npix_max': 421,\n",
       "  'no_long': False,\n",
       "  'no_two': False},\n",
       " 1: {'model': 'ORCA',\n",
       "  'grid': 'latlon',\n",
       "  'start_time': '2015-01-01',\n",
       "  'end_time': '2015-12-31',\n",
       "  'calendar': 'standard',\n",
       "  'lon1': 77.5,\n",
       "  'lon2': 69.5,\n",
       "  'lat1': -67,\n",
       "  'lat2': -30,\n",
       "  'min_dep': 1000,\n",
       "  'res': 0.1,\n",
       "  'OW_thr': array(1.49952532e-10),\n",
       "  'OW_thr_name': 'OW_std',\n",
       "  'OW_thr_factor': -0.3,\n",
       "  'Npix_min': 10,\n",
       "  'Npix_max': 421,\n",
       "  'no_long': False,\n",
       "  'no_two': False}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb610720-daba-4798-bfcd-11010d77cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data for eddy detection (masking and region extracting etc.)\n",
      "detection at time step  1  of  73\n",
      "detection at time step  9  of  73\n",
      "detection at time step  17  of  73\n",
      "detection at time step  25  of  73\n",
      "detection at time step  33  of  73\n",
      "detection at time step  42  of  73\n",
      "detection at time step  50  of  73\n",
      "detection at time step  58  of  73\n",
      "detection at time step  66  of  73\n",
      "preparing data for eddy detection (masking and region extracting etc.)\n",
      "detection at time step  1  of  73\n",
      "detection at time step  9  of  73\n",
      "detection at time step  17  of  73\n",
      "detection at time step  25  of  73\n",
      "detection at time step  33  of  73\n",
      "detection at time step  42  of  73\n",
      "detection at time step  50  of  73\n",
      "detection at time step  58  of  73\n",
      "detection at time step  66  of  73\n"
     ]
    }
   ],
   "source": [
    "eddies={}\n",
    "for i in range(0,len(data_int)):\n",
    "    eddies[i] = et.detection.detect_OW(data_int[i].isel(z=9), detection_parameters[i], 'OW', 'vort', regrid_avoided=False, \n",
    "                                 use_bags=False, use_mp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad863a2e-b201-466e-971d-1f30ae8037f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,len(data_int)):\n",
    "    for i in np.arange(0, len(eddies[j])):\n",
    "        datestring = str(eddies[j][i][0]['time'])[0:10]\n",
    "        with open('./EXP05/onestd_'\n",
    "          + str(datestring) + '_eddies_OW0.3_npmin10_npmax421.pickle', 'wb') as f:\n",
    "            pickle.dump(eddies[j][i], f, pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "859a8c01-26f2-4ac6-96e7-d282496109a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data for eddy detection (masking and region extracting etc.)\n",
      "detection at time step  1  of  73\n",
      "detection at time step  9  of  73\n",
      "detection at time step  17  of  73\n",
      "detection at time step  25  of  73\n",
      "detection at time step  33  of  73\n",
      "detection at time step  42  of  73\n",
      "detection at time step  50  of  73\n",
      "detection at time step  58  of  73\n",
      "detection at time step  66  of  73\n"
     ]
    }
   ],
   "source": [
    "eddies = et.detection.detect_OW(data_int_acc, detection_parameters[0], 'OW_acc', 'vort_acc', regrid_avoided=False, \n",
    "                                 use_bags=False, use_mp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2382c4d3-a3d2-4c4a-a483-2b4d03894e38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for j in range(0,len(data_int)):\n",
    "for i in np.arange(0, len(eddies)):\n",
    "    datestring = str(eddies[i][0]['time'])[0:10]\n",
    "    with open('./ACC/detected/test_'\n",
    "          + str(datestring) + '_eddies_OW0.3_npmin20_npmax200.pickle', 'wb') as f:\n",
    "        pickle.dump(eddies[i], f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd3e47-dc4e-4728-953c-376eade51168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3-eddytools)",
   "language": "python",
   "name": "py3-eddytools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
